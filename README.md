# Workshop on "Machine learning model developments for classification problems"

## Workshop Day 1
1. Covered general introduction to build ML Model
2. Classification problem use case
3. HR analysitcs Data - Context and content of the data
4. Practical Demo using Python Libraries
 - Data Cleaning
 - Data Pre-processing
 - Missing Imputations
 - Exploratory data analysis
 - Feature Engineering
 - Feature Selection

Created a master data with all existing and derived features. We derived ~190 additional features after processing and feature engineering. 

## Workshop Day 2

1. General steps to evaluate ML classification Model
2. Sample Split
 -  Unseen Data
 -  Training Sample
 -  Test Sample
3. Random Forest Model
 -  GLM model development
 -  Predict score on validataion data
 -  Evaluation of the model before optimising the probability cut off
 -  Evaluation of the model after optimising the probability cut off
 -  AUC, Confusion matric and ROC curve
4. XGBoost Model
 -  GLM model development
 -  Predict score on validataion data
 -  Evaluation of the model before optimising the probability cut off
 -  Evaluation of the model after optimising the probability cut off
 -  AUC, Confusion matric and ROC curve
5. Model comparision
6. Ensemble Model and Scoring

## Session Video
https://drive.google.com/drive/folders/1-dS-_u6_Wd-fpD679ISp6WeiVa9pkihC?usp=sharing

## Reference:
0. Data Source:
 - https://www.kaggle.com/arashnic/hr-analytics-job-change-of-data-scientists
2. Logistic Regression
 - https://www.kdnuggets.com/2018/02/logistic-regression-concise-technical-overview.html#%2EWoceyX3ClwM%2Elinkedin![image](https://user-images.githubusercontent.com/17849762/125186922-9a5a5280-e24a-11eb-9bf8-e01db4e03367.png)
 - http://www.real-statistics.com/logistic-regression/receiver-operating-characteristic-roc-curve/![image](https://user-images.githubusercontent.com/17849762/125186930-a219f700-e24a-11eb-8d90-4a062322417e.png)
 - https://medium.com/convoy-tech/down-the-auc-rabbit-hole-and-into-open-source-part-1-42c47e90e357![image](https://user-images.githubusercontent.com/17849762/125186934-ae9e4f80-e24a-11eb-9ada-d3a8e46d92aa.png)

2. Random Forest
 - https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/tutorial-random-forest-parameter-tuning-r/tutorial/
 - https://blog.clairvoyantsoft.com/entropy-information-gain-and-gini-index-the-crux-of-a-decision-tree-99d0cdc699f4
 - https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76
 - https://www.topcoder.com/thrive/articles/understanding-random-forest-and-hyper-parameter-tuning![image](https://user-images.githubusercontent.com/17849762/125186892-70089500-e24a-11eb-8f15-356d38f16b75.png)
 - https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74![image](https://user-images.githubusercontent.com/17849762/125186904-80b90b00-e24a-11eb-9f39-9631e26ecff3.png)

3. XGBoost
 - https://xgboost.readthedocs.io/en/latest/
 - http://explained.ai/gradient-boosting/index.html![image](https://user-images.githubusercontent.com/17849762/125186878-62eba600-e24a-11eb-95d9-355b2641243a.png)
 - https://eng.uber.com/productionizing-distributed-xgboost/
 - https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/
